colnames(Output_Curves)=paste("C",seq(0,40),sep = "")
View(Output_Curves)
#Put all the values in a dataframe
Output_Curves=data.frame(matrix(rep(NA,M*(N+1)),nrow=M,ncol=(N+1)))
dim(Output_Curves)
for (i in 1:M){
Output_Curves[i,]=dfUn[i,][[1]][[1]]
}
colnames(Output_Curves)=paste("U",seq(0,40),sep = "")
View(Output_Curves)
#The stability was already ensured in the code just above.
N=40
M=100
#2. Generate M values of the parameters a, b and c, and M values of U0 ;
a_values=rnorm(M,mean=0.55,sd=0.225)
b_values=rnorm(M,mean=3,sd=1)
c_values=rnorm(M,mean=0.5,sd=0.2)
U0_values=abs(rnorm(M,mean=1,sd=1)) #U0 must be positive, otherwise we get NaN
#Get the list of results corresponding to each M of the combinations in a
#dataframe
dfUn=data.frame(matrix(ncol = ncol(Computed_Outputs), nrow = 0))
names(dfUn)=names(Computed_Outputs)
for (i in 1:M){
dfUn=rbind(dfUn,Give_Output(U0_values[i],N,a_values[i],b_values[i],c_values[i]))
}
#Put all the M curves in a list
List_Curves=list()
library(ggplot2)
par(mfrow=c(1,1))
for (i in 1:M){
unData=as.data.frame(matrix(data=dfUn[i,]$Un[[1]],ncol=1))
colnames(unData)=c("Un")
unData$n=c(1:nrow(unData))
List_Curves[[i]]=
list(N=dfUn[i,]$N,
a=dfUn[i,]$a,
b=dfUn[i,]$b,
c=dfUn[i,]$c,
U0=dfUn[i,]$U0,
Un=dfUn[i,]$Un[[1]],
plot=ggplot(unData, aes(x=c(1:nrow(unData)), y=Un)) + geom_point() +
theme_bw() +
ggtitle(paste("a=",round(x=dfUn[i,]$a,digits =3),
", b=",round(x=dfUn[i,]$b,digits =3),
", c=",round(x=dfUn[i,]$c,digits =3),
", U0=",round(x=dfUn[i,]$U0,digits =3),
", i=", i,sep="")))
}
List_Curves[[2]]
List_Curves[[9]]$plot
#Put all the values in a dataframe
Output_Curves=data.frame(matrix(rep(NA,M*(N+1)),nrow=M,ncol=(N+1)))
dim(Output_Curves)
for (i in 1:M){
Output_Curves[i,]=dfUn[i,][[1]][[1]]
}
colnames(Output_Curves)=paste("U",seq(0,40),sep = "")
View(Output_Curves)
#4. Generate a matrix M x N of random noise components ;
noiseMatrix=as.data.frame(t(rnorm(N,mean=0,sd=0.1)))
#4. Generate a matrix M x N of random noise components ;
noiseMatrix=as.data.frame(t(rnorm(N+1,mean=0,sd=0.1)))
for (i in 2:M){
noiseMatrix[i,]=t(rnorm(N,mean=0,sd=0.1))
}
#4. Generate a matrix M x N of random noise components ;
noiseMatrix=as.data.frame(t(rnorm(N+1,mean=0,sd=0.1)))
for (i in 2:M){
noiseMatrix[i,]=t(rnorm(N+1,mean=0,sd=0.1))
}
View(noiseMatrix)
dim(Output_Curves)
dim(noiseMatrix)
Main_Learning_Base=Output_Curves+noiseMatrix
View(Main_Learning_Base)
dim(Main_Learning_Base)
baseSplit = sample(c(TRUE, FALSE), nrow(Main_Learning_Base), replace=TRUE,
prob=c(0.7, 0.3))
Main_Training_Base = Main_Learning_Base[baseSplit, ]
dim(Main_Training_Base)
Main_Test_Base = Main_Learning_Base[!baseSplit, ]
dim(Main_Test_Base)
#Let us take the sum of the norm 2 distance between each point at a same index
#for the difference between two vectors representing the Y-values of the curves
#each having the same length
CurveDiff=function(Curve1,Curve2){
if (length(Curve1)!=length(Curve2)){
return (NaN)
}
sumDiff=0
for (i in 1:length(Curve1)){
sumDiff=sumDiff+(Curve1[i]-Curve2[i])**2
}
sumDiff=sqrt(sumDiff)
sumDiff
}
CurveDiff(Curve1,Curve2)
Curve1=Main_Training_Base[1,]
Curve2=Main_Training_Base[2,]
CurveDiff(Curve1,Curve2)
Curve1=c(Main_Training_Base[1,])
Curve2=c(Main_Training_Base[2,])
CurveDiff(Curve1,Curve2)
Curve2
Curve1=Main_Training_Base[1,]
Curve2=Main_Training_Base[2,]
Curve1
Curve1=Main_Training_Base[1,]
Curve2=Main_Training_Base[2,]
Curve1
Curve2
CurveDiff(Curve1,Curve2)
Curve1=Main_Training_Base[1,]
Curve2=Main_Training_Base[2,]
CurveDiff(Curve1,Curve2)
Curve1=Main_Training_Base[2,]
Curve2=Main_Training_Base[1,]
CurveDiff(Curve1,Curve2)
Curve1=Main_Training_Base[1,]
Curve2=Main_Training_Base[5,]
CurveDiff(Curve1,Curve2)
Curve1=Main_Training_Base[5,]
Curve2=Main_Training_Base[2,]
CurveDiff(Curve1,Curve2)
names(Main_Learning_Base)
paste("U",seq(0,40),sep = "")
Unames=paste("U",seq(0,40),sep = "")
c(Unames,"a","b","c")
names(dfUn[[1])
names(dfUn[[1]])
names(dfUn[i,][[1]])
names(dfUn)
#Put all the values in a dataframe
Output_Curves=data.frame(matrix(rep(NA,M*(N+6)),nrow=M,ncol=(N+1)))
#Put all the values in a dataframe
Output_Curves=data.frame(matrix(rep(NA,M*(N+4)),nrow=M,ncol=(N+4)))
dim(Output_Curves)
for (i in 1:M){
dfUni=dfUn[i,]
Output_Curves[i,]=c(dfUni[[1]][[1]],dfUni$a,dfUni$b,dfUni$c)
}
colnames(Output_Curves)=c(paste("U",seq(0,40),sep = ""),"a","b","c")
View(Output_Curves)
#Put all the values in a dataframe
Output_Curves=data.frame(matrix(rep(NA,M*(N+4)),nrow=M,ncol=(N+4)))
dim(Output_Curves)
for (i in 1:M){
dfUni=dfUn[i,]
Output_Curves[i,]=c(dfUni$a,dfUni$b,dfUni$c,dfUni[[1]][[1]])
}
colnames(Output_Curves)=c("a","b","c",paste("U",seq(0,40),sep = ""))
View(Output_Curves)
dim(Output_Curves)
#4. Generate a matrix M x N of random noise components ;
noiseMatrix=as.data.frame(t(rnorm(N+1,mean=0,sd=0.1)))
for (i in 2:M){
noiseMatrix[i,]=t(rnorm(N+1,mean=0,sd=0.1))
}
View(noiseMatrix)
dim(noiseMatrix)
Main_Learning_Base=Output_Curves+noiseMatrix
Output_Curves_U=subset(Output_Curves,select = -c("a","b","c"))
dim(Output_Curves_U)
?subset
Output_Curves_U=subset(Output_Curves,select = -c(a,b,c))
dim(Output_Curves_U)
Output_Curves_params=subset(Output_Curves,select = c(a,b,c))
dim(Output_Curves_params)
#Put all the values in a dataframe
Output_Curves=data.frame(matrix(rep(NA,M*(N+4)),nrow=M,ncol=(N+4)))
dim(Output_Curves)
for (i in 1:M){
dfUni=dfUn[i,]
Output_Curves[i,]=c(dfUni$a,dfUni$b,dfUni$c,dfUni[[1]][[1]])
}
colnames(Output_Curves)=c("a","b","c",paste("U",seq(0,40),sep = ""))
View(Output_Curves)
dim(Output_Curves)
Output_Curves_U=subset(Output_Curves,select = -c(a,b,c))
dim(Output_Curves_U)
Output_Curves_params=subset(Output_Curves,select = c(a,b,c))
dim(Output_Curves_params)
#4. Generate a matrix M x N of random noise components ;
noiseMatrix=as.data.frame(t(rnorm(N+1,mean=0,sd=0.1)))
for (i in 2:M){
noiseMatrix[i,]=t(rnorm(N+1,mean=0,sd=0.1))
}
View(noiseMatrix)
dim(noiseMatrix)
Main_Learning_Base=Output_Curves_U+noiseMatrix
View(Main_Learning_Base)
Main_Learning_Base=cbind(Output_Curves_params,Main_Learning_Base)
dim(Main_Learning_Base)
colnames(Main_Learning_Base)=colnames(Output_Curves)
View(Main_Learning_Base)
baseSplit = sample(c(TRUE, FALSE), nrow(Main_Learning_Base), replace=TRUE,
prob=c(0.7, 0.3))
Main_Training_Base = Main_Learning_Base[baseSplit, ]
dim(Main_Training_Base)
Main_Test_Base = Main_Learning_Base[!baseSplit, ]
dim(Main_Test_Base)
#Let us take the sum of the norm 2 distance between each point at a same index
#for the difference between two vectors representing the Y-values of the curves
#each having the same length
CurveDiff=function(Curve1,Curve2){
if (length(Curve1)!=length(Curve2)){
return (NaN)
}
sumDiff=0
for (i in 1:length(Curve1)){
sumDiff=sumDiff+(Curve1[i]-Curve2[i])**2
}
sumDiff=sqrt(sumDiff)
sumDiff
}
Curve1=Main_Training_Base[1,]
Curve2=Main_Training_Base[2,]
CurveDiff(Curve1,Curve2)
Curve1=Main_Training_Base[2,]
Curve2=Main_Training_Base[1,]
CurveDiff(Curve1,Curve2)
Generate_Output(60,N,1,5,0.2)
Generate_Output(60,N,1,5,0.2)$Un
?mapply
?seq
# 4. Let All U0 a vector containing a list of values of U0. Describe what the
# following function does :
a_t=0.5
b_t=3
c_t=0.5
All_U0=seq(from=1, to=10, by=1)
Predicted_Curves <- mapply(Generate_Output, All_U0 , N, a_t , b_t , c_t )
Predicted_Curves
set.seed(12345) #for reproductibility
N=7
a=5
b=6
c=0.05
U0=2
Un=list(U0)
for (i in 1:N){
Un[i+1]=a*Un[[i]]**c+b
}
Un
Computed_Outputs=data.frame(matrix(ncol = 6, nrow = 0))
names(Computed_Outputs)=c("Un","U0","N","a","b","c")
Computed_Outputs=rbind(Computed_Outputs,
data.frame(Un=I(list(Un)),U0=U0,N=N,a=a,b=b,c=c))
#This is the variable where the results are stored
Computed_Outputs
Generate_Output = function(U0, N, a, b, c){
Un=c(U0)
for (i in 1:N){
Un[i+1]=a*Un[i]**c+b
}
#<<- to update the global variable
Computed_Outputs<<-rbind(Computed_Outputs,
data.frame(Un=I(list(Un)),U0=U0,N=N,a=a,b=b,c=c))
#returned result
data.frame(Un=I(list(Un)),U0=U0,N=N,a=a,b=b,c=c)
}
#Function to check whether the result is already available and return it
# or compute it if needed
Give_Output = function(U0, N, a, b, c){
already_Computed=Computed_Outputs[Computed_Outputs["U0"]==U0 &
Computed_Outputs["N"]==N &
Computed_Outputs["a"]==a &
Computed_Outputs["b"]==b &
Computed_Outputs["c"]==c,]
if (nrow(already_Computed)>=1){
Result_Output=already_Computed[1,]
}else{
Result_Output=Generate_Output(U0, N, a, b, c)
}
Result_Output
}
# 4. Let N = 40, a ??? [2; 5], b ??? [1; 5] and , c ??? [0.1; 0.9]. For different
#values of a, b and c, generate 6 curves. Present the results by specifying the
#values of a, b and c
noCurves=9 #We choose 9 curves instead of 6 for more accuracy
U0=1
N=40
#Function to provide the list of Un depending on a list of parameters
curveValuesFunc = function(a,b,c){
curveValues=data.frame(matrix(ncol = 3, nrow = 0))
for (i in 1:noCurves){
curveValuesi=c(a[i],b[i],c[i])
curveValues=rbind(curveValues,curveValuesi)
}
names(curveValues)=c("a", "b", "c")
#Get the list of results corresponding to each noCurves of the combinations
#in a dataframe
dfUn=data.frame(matrix(ncol = ncol(Computed_Outputs), nrow = 0))
names(dfUn)=names(Computed_Outputs)
for (i in 1:noCurves){
dfUn=rbind(dfUn,Give_Output(U0,N,
curveValues[i,]$a,
curveValues[i,]$b,
curveValues[i,]$c))
}
list(curveValues,dfUn)
}
#Function to print the curves
printCurveValues = function(a,b,c){
#Get the list of results corresponding to each noCurves of the combinations in
#a dataframe
listUn=curveValuesFunc(a,b,c)
curveValues=listUn[[1]]
dfUn=listUn[[2]]
#Print the curves
par(mfrow=c(noCurves/3,3))
for (i in 1:nrow(dfUn)){
plot(dfUn[i,]$Un[[1]], xlab="n",ylab="Una",main=paste(
"a=",round(x=curveValues[i,]$a,digits =3),
", b=",round(x=curveValues[i,]$b,digits =3),
", c=",round(x=curveValues[i,]$c,digits =3),sep=""))
}
}
#Print ordered by a value
aa=seq(from=2,to=5,length.out=noCurves)
ba=rep(3,noCurves)
ca=rep(0.5,noCurves)
printCurveValues(aa,ba,ca)
#Print ordered by b value
ab=rep(3.5,noCurves)
bb=seq(from=1,to=5,length.out=noCurves)
cb=rep(0.5,noCurves)
printCurveValues(ab,bb,cb)
#Print ordered by c value
ac=rep(3.5,noCurves)
bc=rep(3,noCurves)
cc=seq(from=0.1,to=0.9,length.out=noCurves)
printCurveValues(ac,bc,cc)
#You can run the following commands to see that influence,
#after executing the commands above.
#For a:
printCurveValues(aa,ba,ca)
#For b:
printCurveValues(ab,bb,cb)
#For c:
printCurveValues(ac,bc,cc)
#Parameter a:
aa=seq(from=2,to=5,length.out=noCurves)
ba=rep(3,noCurves)
ca=rep(0.5,noCurves)
dfUna=curveValuesFunc(aa,ba,ca)[[2]]
UnaMax=data.frame(matrix(ncol = 2, nrow = 0))
for (i in 1:nrow(dfUna)){
UnaMaxi=c(dfUna[i,]$a,max(dfUna[i,]$Un[[1]]))
UnaMax=rbind(UnaMax,UnaMaxi)
}
names(UnaMax)=c("a","Maxa")
UnaMax
#The result is multiplied by 3.411878
max(UnaMax$Maxa)/min(UnaMax$Maxa)
#when we multiply a by 2.5
max(UnaMax$a)/min(UnaMax$a)
#so the growth by multiplication is of 1.364751
(max(UnaMax$Maxa)/min(UnaMax$Maxa))/((max(UnaMax$a)/min(UnaMax$a)))
#With a gradient:
((max(UnaMax$Maxa)-min(UnaMax$Maxa)))/((max(UnaMax$a)-min(UnaMax$a)))
#Parameter b:
ab=rep(3.5,noCurves)
bb=seq(from=1,to=5,length.out=noCurves)
cb=rep(0.5,noCurves)
dfUnb=curveValuesFunc(ab,bb,cb)[[2]]
UnbMax=data.frame(matrix(ncol = 2, nrow = 0))
for (i in 1:nrow(dfUnb)){
UnbMaxi=c(dfUnb[i,]$b,max(dfUnb[i,]$Un[[1]]))
UnbMax=rbind(UnbMax,UnbMaxi)
}
names(UnbMax)=c("b","Maxb")
UnbMax
#The result is multiplied by 1.485463
max(UnbMax$Maxb)/min(UnbMax$Maxb)
#when we multiply b by 5
max(UnbMax$b)/min(UnbMax$b)
#so the growth by multiplication is of 0.2970926
(max(UnbMax$Maxb)/min(UnbMax$Maxb))/((max(UnbMax$b)/min(UnbMax$b)))
#With a gradient:
(max(UnbMax$Maxb)-min(UnbMax$Maxb))/((max(UnbMax$b)-min(UnbMax$b)))
#Parameter c:
ac=rep(3.5,noCurves)
bc=rep(3,noCurves)
cc=seq(from=0.1,to=0.9,length.out=noCurves)
dfUnc=curveValuesFunc(ac,bc,cc)[[2]]
UncMax=data.frame(matrix(ncol = 2, nrow = 0))
for (i in 1:nrow(dfUnc)){
UncMaxi=c(dfUnc[i,]$c,max(dfUnc[i,]$Un[[1]]))
UncMax=rbind(UncMax,UncMaxi)
}
names(UncMax)=c("c","Maxc")
UncMax
#The result is multiplied by 32023.49
max(UncMax$Maxc)/min(UncMax$Maxc)
#when we multiply c by 9
max(UncMax$c)/min(UncMax$c)
#so the growth by multiplication is of 3558.166
(max(UncMax$Maxc)/min(UncMax$Maxc))/((max(UncMax$c)/min(UncMax$c)))
#With a gradient:
(max(UncMax$Maxc)-min(UncMax$Maxc))/((max(UncMax$c)-min(UncMax$c)))
#Note that we can do the same with different values for the other parameters
#Second example for a
aa=seq(from=2,to=5,length.out=noCurves)
ba=rep(1,noCurves)
ca=rep(0.1,noCurves)
dfUna=curveValuesFunc(aa,ba,ca)[[2]]
UnaMax=data.frame(matrix(ncol = 2, nrow = 0))
for (i in 1:nrow(dfUna)){
UnaMaxi=c(dfUna[i,]$a,max(dfUna[i,]$Un[[1]]))
UnaMax=rbind(UnaMax,UnaMaxi)
}
names(UnaMax)=c("a","Maxa")
UnaMax
#The result is multiplied by 2.178657 instead of 3.411878
max(UnaMax$Maxa)/min(UnaMax$Maxa)
#when we multiply a by 2.5, the max doesn't change
max(UnaMax$a)/min(UnaMax$a)
#so the growth by multiplication is of 0.8714626 instead of 1.364751
(max(UnaMax$Maxa)/min(UnaMax$Maxa))/((max(UnaMax$a)/min(UnaMax$a)))
#With a gradient:
((max(UnaMax$Maxa)-min(UnaMax$Maxa)))/((max(UnaMax$a)-min(UnaMax$a)))
#of the model for those parameters.
#We also try to do the same for the same parameters, except that for
#the parameter we evaluate, we increment it a little, and we compare
#both results with a subtraction.
#We then divide the result of that subtraction by the increment of
#the parameter.
#Last we sum all those differences (in absolute value in order to get
#distances), and we divide it by the number of iterations over that parameter
#in order to get an average value.
#The value we get is considered as the sensitivity indicator
avgSensitivyIndicator =
function(U0,amin,amax,bmin,bmax,cmin,cmax,abclen,paramname){
aseq=seq(from=amin,to=amax,length.out=abclen)
bseq=seq(from=bmin,to=bmax,length.out=abclen)
cseq=seq(from=cmin,to=cmax,length.out=abclen)
sensi=0
if (paramname=="a"){
for (i in 1:(abclen-1)){
for (bi in bseq){
for (ci in cseq){
ai1=aseq[i]
ai2=aseq[i+1]
sensi=sensi+
abs(max(Give_Output(U0,abclen,ai2,bi,ci)$Un[[1]])-
max(Give_Output(U0,abclen,ai1,bi,ci)$Un[[1]]))/
abs(ai2-ai1)
}
}
}
}
if (paramname=="b"){
for (i in 1:(abclen-1)){
for (ci in cseq){
for (ai in aseq){
bi1=bseq[i]
bi2=bseq[i+1]
sensi=sensi+
abs(max(Give_Output(U0,abclen,ai,bi2,ci)$Un[[1]])-
max(Give_Output(U0,abclen,ai,bi1,ci)$Un[[1]]))/
abs(bi2-bi1)
}
}
}
}
if (paramname=="c"){
for (i in 1:(abclen-1)){
for (ai in aseq){
for (bi in bseq){
ci1=cseq[i]
ci2=cseq[i+1]
sensi=sensi+
abs(max(Give_Output(U0,abclen,ai,bi,ci2)$Un[[1]])-
max(Give_Output(U0,abclen,ai,bi,ci1)$Un[[1]]))/
abs(ci2-ci1)
}
}
}
}
return(sensi/abclen)
}
U0=1
amin=2
amax=5
bmin=1
bmax=5
cmin=0.1
cmax=0.9
abclen=10
#4. Compute the value of your indicator associated to each parameter ;
paramname="a"
avgSensitivyIndicator(U0,amin,amax,bmin,bmax,cmin,cmax,abclen,paramname)
#141769.6
paramname="b"
avgSensitivyIndicator(U0,amin,amax,bmin,bmax,cmin,cmax,abclen,paramname)
#7578.562
paramname="c"
avgSensitivyIndicator(U0,amin,amax,bmin,bmax,cmin,cmax,abclen,paramname)
U0=1
amin=2
amax=5
bmin=1
bmax=5
cmin=0.1
cmax=0.9
abclen=10
avgSensitivyIndicator(U0,amin,amax,bmin,bmax,cmin,cmax,abclen,paramname="a")
#141769.6
amin=0.1
amax=2
avgSensitivyIndicator(U0,amin,amax,bmin,bmax,cmin,cmax,abclen,paramname="a")
